{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08b36226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv(\"data/train_data_With_features.csv\")\n",
    "test_data = pd.read_csv(\"data/test_data_with_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50b8d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_students = pd.read_csv(\"processed_train_student.csv\")\n",
    "# Rename uid to id to match train_data\n",
    "train_students = train_students.rename(columns={\"UID\": \"id\"})\n",
    "# Merge train data with student data\n",
    "merged_df = pd.merge(train_data, train_students, on=\"id\", how=\"left\")\n",
    "train_data = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80a2834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # adjust max_features if needed\n",
    "tfidf_embeddings = tfidf_vectorizer.fit_transform(train_data[\"answers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f6dcec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_features = ['char_count', 'word_count', 'java_keyword_count', \n",
    "                 'method_count', 'class_count', \n",
    "                 'NaN_count', 'comment_count']\n",
    "\n",
    "X_struct = train_data[hand_features].fillna(0).values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67768190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ScoreScaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cee2b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_tfidf = hstack([tfidf_embeddings, X_struct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23aae7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:04<00:00, 10.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load pretrained Sentence-BERT\n",
    "bert_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = AutoModel.from_pretrained(bert_model_name)\n",
    "\n",
    "def get_bert_embedding(texts):\n",
    "    embeddings = []\n",
    "    for text in tqdm(texts):\n",
    "        inputs = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "            last_hidden_state = outputs.last_hidden_state  # (1, seq_len, hidden_size)\n",
    "            # Average pooling\n",
    "            embedding = last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings\n",
    "\n",
    "bert_embeddings = get_bert_embedding(train_data[\"answers\"].tolist())\n",
    "\n",
    "bert_array = np.array(bert_embeddings)\n",
    "\n",
    "if hasattr(X_struct, \"toarray\"):\n",
    "    X_struct_dense = X_struct.toarray()\n",
    "else:\n",
    "    X_struct_dense = X_struct  # already dense\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_struct_scaled = scaler.fit_transform(X_struct_dense)\n",
    "\n",
    "# Now safely combine them\n",
    "X_combined_bert = np.hstack([bert_array, X_struct_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "682618fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:10<00:00,  4.13it/s]\n"
     ]
    }
   ],
   "source": [
    "codebert_model_name = \"microsoft/codebert-base\"\n",
    "codebert_tokenizer = AutoTokenizer.from_pretrained(codebert_model_name)\n",
    "codebert_model = AutoModel.from_pretrained(codebert_model_name)\n",
    "\n",
    "def get_codebert_embedding(texts):\n",
    "    embeddings = []\n",
    "    for text in tqdm(texts):\n",
    "        inputs = codebert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = codebert_model(**inputs)\n",
    "            last_hidden_state = outputs.last_hidden_state\n",
    "            embedding = last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings\n",
    "\n",
    "codebert_embeddings = get_codebert_embedding(train_data[\"answers\"].tolist())\n",
    "\n",
    "codebert_array = np.array(codebert_embeddings)\n",
    "\n",
    "if hasattr(X_struct, \"toarray\"):\n",
    "    X_struct_dense = X_struct.toarray()\n",
    "else:\n",
    "    X_struct_dense = X_struct\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_struct_scaled = scaler.fit_transform(X_struct_dense)\n",
    "\n",
    "X_combined_codebert = np.hstack([codebert_array, X_struct_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10292350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "tokenized_texts = train_data[\"answers\"].apply(simple_preprocess).tolist()\n",
    "w2v_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "def average_vector(tokens, model, vector_size):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "    \n",
    "word2vec_array = np.array([average_vector(tokens, w2v_model, 100) for tokens in tokenized_texts])\n",
    "    \n",
    "X_struct_dense = X_struct.toarray() if hasattr(X_struct, \"toarray\") else X_struct\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_struct_scaled = scaler.fit_transform(X_struct_dense)\n",
    "\n",
    "# Combine\n",
    "X_combined_w2v = np.hstack([word2vec_array, X_struct_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acf9762d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:01<00:00, 10.01it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  4.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings for test data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # adjust max_features if needed\n",
    "tfidf_embeddings = tfidf_vectorizer.fit_transform(test_data[\"answers\"])\n",
    "\n",
    "hand_features = ['char_count', 'word_count', 'java_keyword_count', \n",
    "                 'method_count', 'class_count', \n",
    "                 'NaN_count', 'comment_count']\n",
    "\n",
    "X_struct = test_data[hand_features].fillna(0).values \n",
    "\n",
    "Test_X_tfidf = hstack([tfidf_embeddings, X_struct])\n",
    "\n",
    "#---------\n",
    "\n",
    "bert_embeddings = get_bert_embedding(test_data[\"answers\"].tolist())\n",
    "\n",
    "bert_array = np.array(bert_embeddings)\n",
    "\n",
    "if hasattr(X_struct, \"toarray\"):\n",
    "    X_struct_dense = X_struct.toarray()\n",
    "else:\n",
    "    X_struct_dense = X_struct  # already dense\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_struct_scaled = scaler.fit_transform(X_struct_dense)\n",
    "\n",
    "# Now safely combine them\n",
    "Test_X_combined_bert = np.hstack([bert_array, X_struct_scaled])\n",
    "\n",
    "#---------\n",
    "\n",
    "codebert_embeddings = get_codebert_embedding(test_data[\"answers\"].tolist())\n",
    "\n",
    "codebert_array = np.array(codebert_embeddings)\n",
    "\n",
    "if hasattr(X_struct, \"toarray\"):\n",
    "    X_struct_dense = X_struct.toarray()\n",
    "else:\n",
    "    X_struct_dense = X_struct\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_struct_scaled = scaler.fit_transform(X_struct_dense)\n",
    "\n",
    "Test_X_combined_codebert = np.hstack([codebert_array, X_struct_scaled])\n",
    "\n",
    "#---------\n",
    "tokenized_texts = test_data[\"answers\"].apply(simple_preprocess).tolist()\n",
    "\n",
    "word2vec_array = np.array([average_vector(tokens, w2v_model, 100) for tokens in tokenized_texts])\n",
    "    \n",
    "X_struct_dense = X_struct.toarray() if hasattr(X_struct, \"toarray\") else X_struct\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_struct_scaled = scaler.fit_transform(X_struct_dense)\n",
    "\n",
    "# Combine\n",
    "Test_X_combined_w2v = np.hstack([word2vec_array, X_struct_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "760a7b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.18351869, 41.01678813,  7.56765573, 13.01352715,  6.47608599,\n",
       "       11.85045307, 17.59043877, 16.97506138, 23.07993855, 10.77043512,\n",
       "       12.18307473,  8.02037458, 11.46845305])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_train = X_combined_w2v\n",
    "y_train = train_data[\"FinalClass\"].values  # Assuming 'FinalClass' is the target variable\n",
    "X_test = Test_X_combined_w2v\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cbd1481e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec -> MSE: 54.2164, R²: -2.7663\n",
      "TF-IDF -> MSE: 25.9406, R²: -0.8020\n",
      "BERT -> MSE: 212.6893, R²: -13.7752\n",
      "CodeBERT -> MSE: 191.9950, R²: -12.3376\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "embeddings = {\n",
    "    \"Word2Vec\" : X_combined_w2v,\n",
    "    \"TF-IDF\": X_tfidf,\n",
    "    \"BERT\": X_combined_bert,\n",
    "    \"CodeBERT\": X_combined_codebert,\n",
    "}\n",
    "\n",
    "y = train_data[\"FinalClass\"].values  # Assuming 'score' is the target variable\n",
    "#y = ScoreScaler.fit_transform(y.reshape(-1, 1)).flatten()  # Scale the target variable\n",
    "\n",
    "for name, X in embeddings.items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{name} -> MSE: {mse:.4f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67db3214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Embedding: TF-IDF ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Talha\\miniconda3\\envs\\bitirme\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.219825193448287, tolerance: 0.11169772727272728\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\Users\\Talha\\miniconda3\\envs\\bitirme\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.2402449310428665, tolerance: 0.11169772727272728\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Embedding: BERT ===\n",
      "\n",
      "=== Embedding: CodeBERT ===\n",
      "\n",
      "=== Embedding: Word2Vec ===\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Embedding dictionaries: add your actual numpy arrays here\n",
    "embeddings = {\n",
    "    \"TF-IDF\": X_tfidf,\n",
    "    \"BERT\": X_combined_bert,\n",
    "    \"CodeBERT\": X_combined_codebert,\n",
    "    \"Word2Vec\": X_combined_w2v\n",
    "}\n",
    "\n",
    "# Regression models to try\n",
    "regressors = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(),\n",
    "    \"RandomForest\": RandomForestRegressor(),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "    \"MLP\": MLPRegressor(max_iter=10000)\n",
    "}\n",
    "\n",
    "# Target values\n",
    "y = train_data[\"FinalClass\"].values\n",
    "\n",
    "# Run all combos\n",
    "for embed_name, X in embeddings.items():\n",
    "    print(f\"\\n=== Embedding: {embed_name} ===\")\n",
    "    \n",
    "    #X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "\n",
    "    if embed_name == \"TF-IDF\":\n",
    "        X_test = Test_X_tfidf\n",
    "    elif embed_name == \"BERT\":\n",
    "        X_test = Test_X_combined_bert\n",
    "    elif embed_name == \"CodeBERT\":\n",
    "        X_test = Test_X_combined_codebert\n",
    "    elif embed_name == \"Word2Vec\":\n",
    "        X_test = Test_X_combined_w2v\n",
    "\n",
    "    \n",
    "    for model_name, model in regressors.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        #y_pred = ScoreScaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "        # Combine with test data write to CSV\n",
    "        test_data[f\"{embed_name}_{model_name}_pred\"] = y_pred\n",
    "        test_data = test_data[[\"id\",f\"{embed_name}_{model_name}_pred\"]]\n",
    "        test_data.to_csv(f\"predictions/{embed_name}_{model_name}_predictions.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ef13439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>NaN_count</th>\n",
       "      <th>answers</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>java_keyword_count</th>\n",
       "      <th>method_count</th>\n",
       "      <th>class_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>predicted_score</th>\n",
       "      <th>...</th>\n",
       "      <th>Word2Vec_LinearRegression_pred</th>\n",
       "      <th>Word2Vec_Ridge_pred</th>\n",
       "      <th>Word2Vec_Lasso_pred</th>\n",
       "      <th>Word2Vec_ElasticNet_pred</th>\n",
       "      <th>Word2Vec_DecisionTree_pred</th>\n",
       "      <th>Word2Vec_RandomForest_pred</th>\n",
       "      <th>Word2Vec_GradientBoosting_pred</th>\n",
       "      <th>Word2Vec_SVR_pred</th>\n",
       "      <th>Word2Vec_KNN_pred</th>\n",
       "      <th>Word2Vec_MLP_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4380745</td>\n",
       "      <td>1</td>\n",
       "      <td>recursion 1) collatz problemi. bu kısımda amac...</td>\n",
       "      <td>212997</td>\n",
       "      <td>24761</td>\n",
       "      <td>4249</td>\n",
       "      <td>990</td>\n",
       "      <td>157</td>\n",
       "      <td>378</td>\n",
       "      <td>-2.923501</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.923501</td>\n",
       "      <td>13.732007</td>\n",
       "      <td>12.775774</td>\n",
       "      <td>12.951710</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.135064</td>\n",
       "      <td>11.193706</td>\n",
       "      <td>14.6</td>\n",
       "      <td>10.427960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8190737</td>\n",
       "      <td>4</td>\n",
       "      <td>recursion 1) collatz problemi. bu kısımda amac...</td>\n",
       "      <td>103887</td>\n",
       "      <td>12667</td>\n",
       "      <td>2034</td>\n",
       "      <td>516</td>\n",
       "      <td>131</td>\n",
       "      <td>79</td>\n",
       "      <td>35.792701</td>\n",
       "      <td>...</td>\n",
       "      <td>35.792701</td>\n",
       "      <td>10.226926</td>\n",
       "      <td>9.134894</td>\n",
       "      <td>9.103846</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.89</td>\n",
       "      <td>11.792672</td>\n",
       "      <td>9.182130</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.278004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8964453</td>\n",
       "      <td>9</td>\n",
       "      <td>müzik çalar simülasyonu bil 211 - laboratuvar ...</td>\n",
       "      <td>105989</td>\n",
       "      <td>13683</td>\n",
       "      <td>2331</td>\n",
       "      <td>569</td>\n",
       "      <td>84</td>\n",
       "      <td>104</td>\n",
       "      <td>8.968522</td>\n",
       "      <td>...</td>\n",
       "      <td>8.968522</td>\n",
       "      <td>6.456905</td>\n",
       "      <td>6.871091</td>\n",
       "      <td>7.099719</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.36</td>\n",
       "      <td>12.316183</td>\n",
       "      <td>7.796521</td>\n",
       "      <td>7.8</td>\n",
       "      <td>13.597991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2384475</td>\n",
       "      <td>2</td>\n",
       "      <td>2384475 recursion 1) collatz problemi. bu kısı...</td>\n",
       "      <td>129912</td>\n",
       "      <td>16263</td>\n",
       "      <td>2756</td>\n",
       "      <td>684</td>\n",
       "      <td>113</td>\n",
       "      <td>139</td>\n",
       "      <td>12.620797</td>\n",
       "      <td>...</td>\n",
       "      <td>12.620797</td>\n",
       "      <td>10.985350</td>\n",
       "      <td>10.596030</td>\n",
       "      <td>10.220092</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.07</td>\n",
       "      <td>13.000915</td>\n",
       "      <td>10.731128</td>\n",
       "      <td>10.6</td>\n",
       "      <td>13.103578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4540765</td>\n",
       "      <td>10</td>\n",
       "      <td>4540765 recursion 1) collatz problemi. bu kısı...</td>\n",
       "      <td>117853</td>\n",
       "      <td>14921</td>\n",
       "      <td>2864</td>\n",
       "      <td>614</td>\n",
       "      <td>81</td>\n",
       "      <td>140</td>\n",
       "      <td>3.156128</td>\n",
       "      <td>...</td>\n",
       "      <td>3.156128</td>\n",
       "      <td>5.651518</td>\n",
       "      <td>6.654997</td>\n",
       "      <td>7.075588</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.18</td>\n",
       "      <td>7.871240</td>\n",
       "      <td>8.176377</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.482622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6418019</td>\n",
       "      <td>4</td>\n",
       "      <td>6418019 recursion 1) collatz problemi. bu kısı...</td>\n",
       "      <td>130178</td>\n",
       "      <td>15554</td>\n",
       "      <td>2626</td>\n",
       "      <td>598</td>\n",
       "      <td>110</td>\n",
       "      <td>109</td>\n",
       "      <td>7.686998</td>\n",
       "      <td>...</td>\n",
       "      <td>7.686998</td>\n",
       "      <td>9.584546</td>\n",
       "      <td>9.678621</td>\n",
       "      <td>9.477406</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.49</td>\n",
       "      <td>6.077087</td>\n",
       "      <td>9.741088</td>\n",
       "      <td>6.2</td>\n",
       "      <td>11.070102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4114373</td>\n",
       "      <td>2</td>\n",
       "      <td>4114373 recursion 1) collatz problemi. bu kısı...</td>\n",
       "      <td>146646</td>\n",
       "      <td>16779</td>\n",
       "      <td>3163</td>\n",
       "      <td>740</td>\n",
       "      <td>167</td>\n",
       "      <td>60</td>\n",
       "      <td>16.780943</td>\n",
       "      <td>...</td>\n",
       "      <td>16.780943</td>\n",
       "      <td>11.620986</td>\n",
       "      <td>10.942108</td>\n",
       "      <td>11.191332</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.40</td>\n",
       "      <td>12.358523</td>\n",
       "      <td>11.390136</td>\n",
       "      <td>12.8</td>\n",
       "      <td>14.733974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5281670</td>\n",
       "      <td>5</td>\n",
       "      <td>5281670 müzik çalar simülasyonu bil 211 - labo...</td>\n",
       "      <td>100169</td>\n",
       "      <td>12914</td>\n",
       "      <td>1944</td>\n",
       "      <td>527</td>\n",
       "      <td>98</td>\n",
       "      <td>228</td>\n",
       "      <td>17.842262</td>\n",
       "      <td>...</td>\n",
       "      <td>17.842262</td>\n",
       "      <td>8.096104</td>\n",
       "      <td>8.596547</td>\n",
       "      <td>8.340913</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.52</td>\n",
       "      <td>8.761501</td>\n",
       "      <td>8.854359</td>\n",
       "      <td>6.8</td>\n",
       "      <td>12.655030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1280995</td>\n",
       "      <td>1</td>\n",
       "      <td>recursion 1) collatz problemi. bu kısımda amac...</td>\n",
       "      <td>158583</td>\n",
       "      <td>19100</td>\n",
       "      <td>3370</td>\n",
       "      <td>736</td>\n",
       "      <td>189</td>\n",
       "      <td>157</td>\n",
       "      <td>21.279893</td>\n",
       "      <td>...</td>\n",
       "      <td>21.279893</td>\n",
       "      <td>13.888121</td>\n",
       "      <td>11.650433</td>\n",
       "      <td>12.125567</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.54</td>\n",
       "      <td>15.129860</td>\n",
       "      <td>12.209905</td>\n",
       "      <td>12.8</td>\n",
       "      <td>18.028484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2051651</td>\n",
       "      <td>8</td>\n",
       "      <td>recursion 1) collatz problemi. bu kısımda amac...</td>\n",
       "      <td>44223</td>\n",
       "      <td>5549</td>\n",
       "      <td>635</td>\n",
       "      <td>250</td>\n",
       "      <td>56</td>\n",
       "      <td>22</td>\n",
       "      <td>11.239141</td>\n",
       "      <td>...</td>\n",
       "      <td>11.239141</td>\n",
       "      <td>5.743576</td>\n",
       "      <td>6.055157</td>\n",
       "      <td>5.437276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.84</td>\n",
       "      <td>6.587693</td>\n",
       "      <td>8.001342</td>\n",
       "      <td>5.8</td>\n",
       "      <td>13.448054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4779274</td>\n",
       "      <td>2</td>\n",
       "      <td>recursion 1) collatz problemi. bu kısımda amac...</td>\n",
       "      <td>121960</td>\n",
       "      <td>15088</td>\n",
       "      <td>2291</td>\n",
       "      <td>630</td>\n",
       "      <td>117</td>\n",
       "      <td>181</td>\n",
       "      <td>13.358292</td>\n",
       "      <td>...</td>\n",
       "      <td>13.358292</td>\n",
       "      <td>10.513891</td>\n",
       "      <td>10.431574</td>\n",
       "      <td>10.003182</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>9.827560</td>\n",
       "      <td>10.450894</td>\n",
       "      <td>10.6</td>\n",
       "      <td>12.024463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5187413</td>\n",
       "      <td>2</td>\n",
       "      <td>recursion 1) collatz problemi. bu kısımda amac...</td>\n",
       "      <td>126605</td>\n",
       "      <td>16620</td>\n",
       "      <td>2949</td>\n",
       "      <td>715</td>\n",
       "      <td>183</td>\n",
       "      <td>119</td>\n",
       "      <td>10.334238</td>\n",
       "      <td>...</td>\n",
       "      <td>10.334238</td>\n",
       "      <td>10.315419</td>\n",
       "      <td>10.527638</td>\n",
       "      <td>11.099445</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.44</td>\n",
       "      <td>11.477809</td>\n",
       "      <td>11.389645</td>\n",
       "      <td>13.6</td>\n",
       "      <td>11.742109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6914659</td>\n",
       "      <td>3</td>\n",
       "      <td>recursion 1) collatz problemi. bu kısımda amac...</td>\n",
       "      <td>117631</td>\n",
       "      <td>14812</td>\n",
       "      <td>2384</td>\n",
       "      <td>658</td>\n",
       "      <td>120</td>\n",
       "      <td>266</td>\n",
       "      <td>11.899130</td>\n",
       "      <td>...</td>\n",
       "      <td>11.899130</td>\n",
       "      <td>8.989432</td>\n",
       "      <td>9.880590</td>\n",
       "      <td>9.669380</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.98</td>\n",
       "      <td>9.042784</td>\n",
       "      <td>10.284766</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9.980671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  NaN_count                                            answers  \\\n",
       "0   4380745          1  recursion 1) collatz problemi. bu kısımda amac...   \n",
       "1   8190737          4  recursion 1) collatz problemi. bu kısımda amac...   \n",
       "2   8964453          9  müzik çalar simülasyonu bil 211 - laboratuvar ...   \n",
       "3   2384475          2  2384475 recursion 1) collatz problemi. bu kısı...   \n",
       "4   4540765         10  4540765 recursion 1) collatz problemi. bu kısı...   \n",
       "5   6418019          4  6418019 recursion 1) collatz problemi. bu kısı...   \n",
       "6   4114373          2  4114373 recursion 1) collatz problemi. bu kısı...   \n",
       "7   5281670          5  5281670 müzik çalar simülasyonu bil 211 - labo...   \n",
       "8   1280995          1  recursion 1) collatz problemi. bu kısımda amac...   \n",
       "9   2051651          8  recursion 1) collatz problemi. bu kısımda amac...   \n",
       "10  4779274          2  recursion 1) collatz problemi. bu kısımda amac...   \n",
       "11  5187413          2  recursion 1) collatz problemi. bu kısımda amac...   \n",
       "12  6914659          3  recursion 1) collatz problemi. bu kısımda amac...   \n",
       "\n",
       "    char_count  word_count  java_keyword_count  method_count  class_count  \\\n",
       "0       212997       24761                4249           990          157   \n",
       "1       103887       12667                2034           516          131   \n",
       "2       105989       13683                2331           569           84   \n",
       "3       129912       16263                2756           684          113   \n",
       "4       117853       14921                2864           614           81   \n",
       "5       130178       15554                2626           598          110   \n",
       "6       146646       16779                3163           740          167   \n",
       "7       100169       12914                1944           527           98   \n",
       "8       158583       19100                3370           736          189   \n",
       "9        44223        5549                 635           250           56   \n",
       "10      121960       15088                2291           630          117   \n",
       "11      126605       16620                2949           715          183   \n",
       "12      117631       14812                2384           658          120   \n",
       "\n",
       "    comment_count  predicted_score  ...  Word2Vec_LinearRegression_pred  \\\n",
       "0             378        -2.923501  ...                       -2.923501   \n",
       "1              79        35.792701  ...                       35.792701   \n",
       "2             104         8.968522  ...                        8.968522   \n",
       "3             139        12.620797  ...                       12.620797   \n",
       "4             140         3.156128  ...                        3.156128   \n",
       "5             109         7.686998  ...                        7.686998   \n",
       "6              60        16.780943  ...                       16.780943   \n",
       "7             228        17.842262  ...                       17.842262   \n",
       "8             157        21.279893  ...                       21.279893   \n",
       "9              22        11.239141  ...                       11.239141   \n",
       "10            181        13.358292  ...                       13.358292   \n",
       "11            119        10.334238  ...                       10.334238   \n",
       "12            266        11.899130  ...                       11.899130   \n",
       "\n",
       "    Word2Vec_Ridge_pred  Word2Vec_Lasso_pred  Word2Vec_ElasticNet_pred  \\\n",
       "0             13.732007            12.775774                 12.951710   \n",
       "1             10.226926             9.134894                  9.103846   \n",
       "2              6.456905             6.871091                  7.099719   \n",
       "3             10.985350            10.596030                 10.220092   \n",
       "4              5.651518             6.654997                  7.075588   \n",
       "5              9.584546             9.678621                  9.477406   \n",
       "6             11.620986            10.942108                 11.191332   \n",
       "7              8.096104             8.596547                  8.340913   \n",
       "8             13.888121            11.650433                 12.125567   \n",
       "9              5.743576             6.055157                  5.437276   \n",
       "10            10.513891            10.431574                 10.003182   \n",
       "11            10.315419            10.527638                 11.099445   \n",
       "12             8.989432             9.880590                  9.669380   \n",
       "\n",
       "    Word2Vec_DecisionTree_pred  Word2Vec_RandomForest_pred  \\\n",
       "0                         12.0                       10.66   \n",
       "1                         14.0                        9.89   \n",
       "2                         14.0                       11.36   \n",
       "3                         13.0                       12.07   \n",
       "4                          9.0                        9.18   \n",
       "5                         12.0                        7.49   \n",
       "6                         16.0                       11.40   \n",
       "7                          3.0                        7.52   \n",
       "8                         16.0                       13.54   \n",
       "9                          1.0                        5.84   \n",
       "10                        11.0                       11.16   \n",
       "11                        14.0                       11.44   \n",
       "12                        14.0                        9.98   \n",
       "\n",
       "    Word2Vec_GradientBoosting_pred  Word2Vec_SVR_pred  Word2Vec_KNN_pred  \\\n",
       "0                        11.135064          11.193706               14.6   \n",
       "1                        11.792672           9.182130                8.0   \n",
       "2                        12.316183           7.796521                7.8   \n",
       "3                        13.000915          10.731128               10.6   \n",
       "4                         7.871240           8.176377                7.8   \n",
       "5                         6.077087           9.741088                6.2   \n",
       "6                        12.358523          11.390136               12.8   \n",
       "7                         8.761501           8.854359                6.8   \n",
       "8                        15.129860          12.209905               12.8   \n",
       "9                         6.587693           8.001342                5.8   \n",
       "10                        9.827560          10.450894               10.6   \n",
       "11                       11.477809          11.389645               13.6   \n",
       "12                        9.042784          10.284766                9.2   \n",
       "\n",
       "    Word2Vec_MLP_pred  \n",
       "0           10.427960  \n",
       "1           21.278004  \n",
       "2           13.597991  \n",
       "3           13.103578  \n",
       "4            8.482622  \n",
       "5           11.070102  \n",
       "6           14.733974  \n",
       "7           12.655030  \n",
       "8           18.028484  \n",
       "9           13.448054  \n",
       "10          12.024463  \n",
       "11          11.742109  \n",
       "12           9.980671  \n",
       "\n",
       "[13 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46267087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Embedding: BERT ===\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Talha\\miniconda3\\envs\\bitirme\\lib\\site-packages\\sklearn\\model_selection\\_search.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.array(param_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'mlp__activation': 'tanh', 'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': (50, 50), 'mlp__learning_rate': 'constant', 'mlp__max_iter': 1000, 'mlp__solver': 'adam'}\n",
      "Best score (negative MSE): -50.19595597593614\n",
      "Validation MSE: 30.38662233154869\n",
      "\n",
      "=== Embedding: CodeBERT ===\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Talha\\miniconda3\\envs\\bitirme\\lib\\site-packages\\sklearn\\model_selection\\_search.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.array(param_list)\n",
      "c:\\Users\\Talha\\miniconda3\\envs\\bitirme\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'mlp__activation': 'tanh', 'mlp__alpha': 0.0001, 'mlp__hidden_layer_sizes': (100,), 'mlp__learning_rate': 'constant', 'mlp__max_iter': 1000, 'mlp__solver': 'adam'}\n",
      "Best score (negative MSE): -37.376400625931446\n",
      "Validation MSE: 10.122734490111133\n",
      "\n",
      "=== Embedding: Word2Vec ===\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best parameters: {'mlp__activation': 'relu', 'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': (64, 64, 32), 'mlp__learning_rate': 'constant', 'mlp__max_iter': 1000, 'mlp__solver': 'adam'}\n",
      "Best score (negative MSE): -22.60937962132116\n",
      "Validation MSE: 46.438678025654795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Talha\\miniconda3\\envs\\bitirme\\lib\\site-packages\\sklearn\\model_selection\\_search.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.array(param_list)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "mlp = MLPRegressor(random_state=42)\n",
    "\n",
    "embeddings = {\n",
    "    \"BERT\": X_combined_bert,\n",
    "    \"CodeBERT\": X_combined_codebert,\n",
    "    \"Word2Vec\": X_combined_w2v\n",
    "}\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('mlp', mlp)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'mlp__hidden_layer_sizes': [(100,), (50, 50), (100, 50), (64, 64, 32)],\n",
    "    'mlp__activation': ['relu', 'tanh'],\n",
    "    'mlp__solver': ['adam'],\n",
    "    'mlp__alpha': [0.0001, 0.001, 0.01],  # L2 penalty\n",
    "    'mlp__learning_rate': ['constant', 'adaptive'],\n",
    "    'mlp__max_iter': [1000, 2000]\n",
    "}\n",
    "\n",
    "for embed_name, X in embeddings.items():\n",
    "    print(f\"\\n=== Embedding: {embed_name} ===\")\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters:\", grid.best_params_)\n",
    "    print(\"Best score (negative MSE):\", grid.best_score_)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    y_pred = best_model.predict(X_val)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    print(\"Validation MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba0ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Embedding: BERT ===\n",
      "LinearRegression     | MSE: 248.131\n",
      "Ridge                | MSE: 28.938\n",
      "Lasso                | MSE: 9.821\n",
      "ElasticNet           | MSE: 9.109\n",
      "DecisionTree         | MSE: 22.222\n",
      "RandomForest         | MSE: 6.364\n",
      "GradientBoosting     | MSE: 7.903\n",
      "SVR                  | MSE: 18.959\n",
      "KNN                  | MSE: 11.938\n",
      "MLP                  | MSE: 27.103\n",
      "\n",
      "=== Embedding: CodeBERT ===\n",
      "LinearRegression     | MSE: 197.692\n",
      "Ridge                | MSE: 18.696\n",
      "Lasso                | MSE: 10.109\n",
      "ElasticNet           | MSE: 7.956\n",
      "DecisionTree         | MSE: 31.111\n",
      "RandomForest         | MSE: 6.288\n",
      "GradientBoosting     | MSE: 8.655\n",
      "SVR                  | MSE: 18.894\n",
      "KNN                  | MSE: 11.818\n",
      "MLP                  | MSE: 8.500\n",
      "\n",
      "=== Embedding: Word2Vec ===\n",
      "LinearRegression     | MSE: 38.895\n",
      "Ridge                | MSE: 18.057\n",
      "Lasso                | MSE: 5.087\n",
      "ElasticNet           | MSE: 5.675\n",
      "DecisionTree         | MSE: 20.889\n",
      "RandomForest         | MSE: 6.913\n",
      "GradientBoosting     | MSE: 8.805\n",
      "SVR                  | MSE: 14.809\n",
      "KNN                  | MSE: 8.147\n",
      "MLP                  | MSE: 61.212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "word2vec_array = scaler.fit_transform(X_combined_w2v)\n",
    "bert_array = scaler.fit_transform(X_combined_bert)\n",
    "codebert_array = scaler.fit_transform(X_combined_codebert)\n",
    "#tfidf_array = scaler.fit_transform(X_tfidf)\n",
    "\n",
    "# Embedding dictionaries: add your actual numpy arrays here\n",
    "embeddings = {\n",
    "    \"BERT\": bert_array,\n",
    "    \"CodeBERT\": codebert_array,\n",
    "    \"Word2Vec\": word2vec_array\n",
    "}\n",
    "\n",
    "# Regression models to try\n",
    "regressors = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(),\n",
    "    \"RandomForest\": RandomForestRegressor(),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "    \"MLP\": MLPRegressor(max_iter=10000)\n",
    "}\n",
    "\n",
    "# Target values\n",
    "y = train_data[\"FinalClass\"].values\n",
    "\n",
    "# Run all combos\n",
    "for embed_name, X in embeddings.items():\n",
    "    print(f\"\\n=== Embedding: {embed_name} ===\")\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for model_name, model in regressors.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "        print(f\"{model_name:<20} | MSE: {mse:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitirme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
